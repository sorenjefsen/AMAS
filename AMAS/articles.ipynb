{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Normal: the uncertainties of scientific measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Particle-physics: 5 sigma for new discovery.\n",
    "\n",
    "Outliers are often assumed normal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Systematic effects\n",
    "class 1: calibration and background uncertainties. Found using data. falls off $\\sqrt{N}$. \n",
    "\n",
    "class 2: Lack of knowledge, model uncertainty, reading error. \n",
    "\n",
    "class 3: Theoretical uncertainties. How does our approximations etc. affect. \n",
    "\n",
    "Counter by checking against all other experiments, and varying everything in the setup.\n",
    " - Again we are limited by not being able to do this completely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods - Data. \n",
    "Uncertainties can be described $x\\pm k\\;u$ where u is the standard deviation. Usually we have k = 1 or 2. \n",
    "\n",
    "Looking at all the measurements, it was found, that all the combinations $z_{ij} = \\frac{|x_i-x_j|}{\\sqrt{\\sigma_i^2 + \\sigma_j^2}}$, was distributed almost like the student t distribution\n",
    "\n",
    "\n",
    "student t: $f(\\nu, \\sigma)$. \n",
    "\n",
    "$\\nu \\rightarrow \\infty \\implies f \\rightarrow gaussian$. \n",
    "\n",
    "$\\nu \\rightarrow 1 \\implies f \\rightarrow Cauchy$\n",
    "\n",
    "The data $z$. was fount to be a sligtly Caucy student t. \n",
    "\n",
    "$\\\\~\\\\$\n",
    "\n",
    "For correlated data: $z_{ij} = \\frac{|x_i - x_j|}{\\sqrt{\\sigma_i^2 + \\sigma_j^2 - 2 cov(x_i, x_j)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What does he do ? \n",
    "\n",
    "## Datawise:\n",
    "- Chooses quantities with > 5 independant measurements. \n",
    "- Chooses data from a wide range of laboratories. \n",
    "- Tries to remove dependant data. (not completely possible for large diverse dataset)\n",
    "- Calculates heterogeneity inconsistency index $(I^2 \\equiv 1 - dof/\\chi^2)$ for similair studies. Something that measures how closely related they are. \n",
    "- Chooses measure of uncertainty confidence interval to be 68.3% (you can choose something else like 95% if its relevant. )\n",
    "\n",
    "## Methodwise\n",
    "- Chooses to deal with normalized differences. \n",
    "- Estimates uncertainties on z bins by monte carlo. like: for every point $x_i \\pm \\sigma_i$, draw a point within gaussian $\\sigma_i$, and calculate resulting z's. Do this many times to get a measure of uncertainty on z-bins\n",
    "\n",
    "## Results\n",
    "- Describes $\\chi$ and $p$ and the ratio of points within 1, 2, 3, 5, 10 sigmas, for different probability distributions fits. \n",
    "- To fit with student t (even though data isnt perfectly student t), he generated montecarlo values with parameters $f(\\nu_x \\sigma_x)$, and adjusted them to agree the most with the original data. \n",
    "\n",
    "## Uncertainties. \n",
    "- Assumed gaussian. If not gaussian, they are transformed gaussian if possible. \n",
    "- Assumed independant. He discusses the consequence of non-independance ($cov(x_i, x_j)$)\n",
    "- Standard deviation is undefined for student t with $\\nu<2$. This limit is rather Cauchy, meaning uncertainties add linearly instead of quadrature. \n",
    "\n",
    "- He chooses to look at $h_i = \\frac{|x_i - \\overline x|}{\\sqrt{\\sigma_i^2 + \\sigma_{\\overline x}^2}}$, that compares values to an expected value. This is good for gaussian, where the mean is the maximum likelihood. Less good if we dont have a nice idea of the expected value. \n",
    "\n",
    "\n",
    "I STOPPED HERE: READ FROM F. EXPECTATION AND CORRELATION. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
